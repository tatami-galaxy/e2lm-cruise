{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a0b667-c53d-4b2e-af39-1920249215f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, concatenate_datasets, DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d099de6e-f0cc-412f-9f5e-5d54fc88de42",
   "metadata": {},
   "source": [
    "#### MMLU Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d97f4d-c01a-45dd-8b6f-4827fcfe9440",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_task_list =  ['abstract_algebra', 'anatomy', 'astronomy', 'business_ethics', 'clinical_knowledge', 'college_biology', 'college_chemistry', 'college_computer_science', 'college_mathematics', 'college_medicine', 'college_physics', 'computer_security', 'conceptual_physics', 'econometrics', 'electrical_engineering', 'elementary_mathematics', 'formal_logic', 'global_facts', 'high_school_biology', 'high_school_chemistry', 'high_school_computer_science', 'high_school_european_history', 'high_school_geography', 'high_school_government_and_politics', 'high_school_macroeconomics', 'high_school_mathematics', 'high_school_microeconomics', 'high_school_physics', 'high_school_psychology', 'high_school_statistics', 'high_school_us_history', 'high_school_world_history', 'human_aging', 'human_sexuality', 'international_law', 'jurisprudence', 'logical_fallacies', 'machine_learning', 'management', 'marketing', 'medical_genetics', 'miscellaneous', 'moral_disputes', 'moral_scenarios', 'nutrition', 'philosophy', 'prehistory', 'professional_accounting', 'professional_law', 'professional_medicine', 'professional_psychology', 'public_relations', 'security_studies', 'sociology', 'us_foreign_policy', 'virology', 'world_religions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ac3192-7262-4efe-aedb-d452b9ea00fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high school + 'elementary' tasks\n",
    "mmlu_hs_list = [task for task in mmlu_task_list if task.startswith('high') or task.startswith('elementary')]\n",
    "# college + professional tasks\n",
    "mmlu_adv_list = [task for task in mmlu_task_list if task.startswith('college') or task.startswith('professional')]\n",
    "\n",
    "mmlu_hs_dict = {task:None for task in mmlu_hs_list}\n",
    "mmlu_adv_dict = {task:None for task in mmlu_adv_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2f53e5d-b79b-4237-b687-85cd30799efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load mmlu\n",
    "for task in mmlu_hs_list:\n",
    "    mmlu_hs_dict[task] = load_dataset('cais/mmlu', task)\n",
    "\n",
    "for task in mmlu_adv_list:\n",
    "    mmlu_adv_dict[task] = load_dataset('cais/mmlu', task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64bc55b7-e7d0-4939-ab7f-1b19a68ed4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge validation splits\n",
    "hs_val = concatenate_datasets([datadict['validation'] for _, datadict in mmlu_hs_dict.items()])\n",
    "adv_val = concatenate_datasets([datadict['validation'] for _, datadict in mmlu_adv_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19e6ff23-4b69-4b7c-a998-eae7b1a5c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample\n",
    "num_samples = min(len(hs_val), len(adv_val))\n",
    "seed = 42\n",
    "\n",
    "hs_val = hs_val.shuffle(seed=seed).select(list(range(num_samples)))\n",
    "adv_val = adv_val.shuffle(seed=seed).select(list(range(num_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcc608dc-c4b5-4ec7-962d-f6dd53bf6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hs config\n",
    "mmlu_hs_val = DatasetDict({'test':hs_val})\n",
    "# adv config\n",
    "mmlu_adv_val = DatasetDict({'test':adv_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf544d1-672e-4dc3-8de6-4b50a1ed191c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mmlu_hs_val.push_to_hub('Ujan/mmlu_hs_adv_val', config_name='hs')\n",
    "mmlu_adv_val.push_to_hub('Ujan/mmlu_hs_adv_val', config_name='adv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571aa618-6638-4fef-bbf7-61c9278b71cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1700033-39d4-4bef-9222-802b03ae0b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['question', 'subject', 'choices', 'answer'],\n",
       "        num_rows: 380\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmlu_hs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73025738-4ace-4eee-a537-2096c497dfba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "074543e2-53ea-402e-a53f-d9ecb0237ecd",
   "metadata": {},
   "source": [
    "#### Eval on Pythia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f26c17f3-eb73-4962-98d7-68ea0313f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
    "\n",
    "# Two sets of eight models of sizes 70M, 160M, 410M, 1B, 1.4B, 2.8B, 6.9B, and 12B. \n",
    "# For each size, there are two models: one trained on the Pile, \n",
    "# and one trained on the Pile after the dataset has been globally deduplicated.\n",
    "# 143 evenly-spaced checkpoints from step1000 to step143000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b41edf03-0e05-4492-aeaa-6e2aad80a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTNeoXForCausalLM.from_pretrained(\n",
    "    \"EleutherAI/pythia-70m-deduped\",\n",
    "    revision=\"step3000\",\n",
    "    cache_dir=\"./pythia-70m-deduped/step3000\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"EleutherAI/pythia-70m-deduped\",\n",
    "    revision=\"step3000\",\n",
    "    cache_dir=\"./pythia-70m-deduped/step3000\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a70736a9-1228-4c94-b7d3-b62023fd7e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello, I am a newbie, and I am a newbie. I am a newbie, and I am'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"Hello, I am\", return_tensors=\"pt\").to(model.device)\n",
    "tokens = model.generate(**inputs)\n",
    "tokenizer.decode(tokens[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f006daf5-850e-4dc6-9f7a-0dbb4fe9eff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea6148b6-a263-49a2-bc54-fe075e28282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader = DataLoader(hs_val, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96959735-0168-49f3-b7f7-43c9ba20b1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8397371a-b7ba-44a9-8719-750970f57145",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [str(s*1000) for s in range(3, 13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52bcb22f-5893-47e1-bd4b-95764aeebfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'A recessionary gap exists when the short-run equilibrium level of real GDP', 'subject': 'high_school_macroeconomics', 'choices': ['decreases over time', 'equals the full-employment level of real GDP', 'is above the full-employment level of real GDP', 'is below the full-employment level of real GDP'], 'answer': 3}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m hs_val:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(example)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "for step in steps:\n",
    "\n",
    "    model = GPTNeoXForCausalLM.from_pretrained(\n",
    "        \"EleutherAI/pythia-70m-deduped\",\n",
    "        revision=\"step\"+step,\n",
    "        cache_dir=\"./pythia-70m-deduped/step\"+step,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"EleutherAI/pythia-70m-deduped\",\n",
    "        revision=\"step\"+step,\n",
    "        cache_dir=\"./pythia-70m-deduped/step\"+step,\n",
    "    )\n",
    "\n",
    "    for example in hs_val:\n",
    "        print(example)\n",
    "        raise\n",
    "\n",
    "## do eval-harness setup \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f83af15-61dc-4fa3-a706-a4b0b87c4ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
