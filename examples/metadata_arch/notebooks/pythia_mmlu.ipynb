{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4a0b667-c53d-4b2e-af39-1920249215f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
    "from datasets import Dataset\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b789e4cb-aedb-41c5-9fbc-d5972d1ec0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_token = \"token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ece4f-43b5-43dc-8484-24c252e8bfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=openai_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d099de6e-f0cc-412f-9f5e-5d54fc88de42",
   "metadata": {},
   "source": [
    "#### MMLU HS ADV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d97f4d-c01a-45dd-8b6f-4827fcfe9440",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_task_list =  ['abstract_algebra', 'anatomy', 'astronomy', 'business_ethics', 'clinical_knowledge', 'college_biology', 'college_chemistry', 'college_computer_science', 'college_mathematics', 'college_medicine', 'college_physics', 'computer_security', 'conceptual_physics', 'econometrics', 'electrical_engineering', 'elementary_mathematics', 'formal_logic', 'global_facts', 'high_school_biology', 'high_school_chemistry', 'high_school_computer_science', 'high_school_european_history', 'high_school_geography', 'high_school_government_and_politics', 'high_school_macroeconomics', 'high_school_mathematics', 'high_school_microeconomics', 'high_school_physics', 'high_school_psychology', 'high_school_statistics', 'high_school_us_history', 'high_school_world_history', 'human_aging', 'human_sexuality', 'international_law', 'jurisprudence', 'logical_fallacies', 'machine_learning', 'management', 'marketing', 'medical_genetics', 'miscellaneous', 'moral_disputes', 'moral_scenarios', 'nutrition', 'philosophy', 'prehistory', 'professional_accounting', 'professional_law', 'professional_medicine', 'professional_psychology', 'public_relations', 'security_studies', 'sociology', 'us_foreign_policy', 'virology', 'world_religions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ac3192-7262-4efe-aedb-d452b9ea00fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high school + 'elementary' tasks\n",
    "mmlu_hs_list = [task for task in mmlu_task_list if task.startswith('high') or task.startswith('elementary')]\n",
    "# college + professional tasks\n",
    "mmlu_adv_list = [task for task in mmlu_task_list if task.startswith('college') or task.startswith('professional')]\n",
    "\n",
    "mmlu_hs_dict = {task:None for task in mmlu_hs_list}\n",
    "mmlu_adv_dict = {task:None for task in mmlu_adv_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2f53e5d-b79b-4237-b687-85cd30799efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load mmlu\n",
    "for task in mmlu_hs_list:\n",
    "    mmlu_hs_dict[task] = load_dataset('cais/mmlu', task)\n",
    "\n",
    "for task in mmlu_adv_list:\n",
    "    mmlu_adv_dict[task] = load_dataset('cais/mmlu', task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64bc55b7-e7d0-4939-ab7f-1b19a68ed4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge validation splits\n",
    "hs_val = concatenate_datasets([datadict['validation'] for _, datadict in mmlu_hs_dict.items()])\n",
    "adv_val = concatenate_datasets([datadict['validation'] for _, datadict in mmlu_adv_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19e6ff23-4b69-4b7c-a998-eae7b1a5c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample\n",
    "num_samples = min(len(hs_val), len(adv_val))\n",
    "seed = 42\n",
    "\n",
    "hs_val = hs_val.shuffle(seed=seed).select(list(range(num_samples)))\n",
    "adv_val = adv_val.shuffle(seed=seed).select(list(range(num_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcc608dc-c4b5-4ec7-962d-f6dd53bf6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hs config\n",
    "mmlu_hs_val = DatasetDict({'test':hs_val})\n",
    "# adv config\n",
    "mmlu_adv_val = DatasetDict({'test':adv_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf544d1-672e-4dc3-8de6-4b50a1ed191c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mmlu_hs_val.push_to_hub('Ujan/mmlu_hs_adv_val', config_name='hs')\n",
    "mmlu_adv_val.push_to_hub('Ujan/mmlu_hs_adv_val', config_name='adv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a5daa9-a8e1-48e2-a2b9-87e9f319a6c1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7aac9419-82d6-43be-9b0e-ecfad8ac7bca",
   "metadata": {},
   "source": [
    "#### MMLU LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f83af15-61dc-4fa3-a706-a4b0b87c4ba4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba6c76608de4dbeb421c1e2f2ead609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/3.50M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecabf81638bd4535aa7086404342e276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/408k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2730d39e68458898aa6ca63c73b8c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev-00000-of-00001.parquet:   0%|          | 0.00/76.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb13b96895746ca9967f8ca6f748128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "auxiliary_train-00000-of-00001.parquet:   0%|          | 0.00/47.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613515e11d274250be88f5c4529fb740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/14042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1570aaadea8945889e46bb1007f177ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1531 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbabc1941784f28881c3f8f448de343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/285 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f5d0c09a4d406899a8cff3e2ea1069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating auxiliary_train split:   0%|          | 0/99842 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mmlu = load_dataset('cais/mmlu', 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e5eb18b-e1eb-439e-a9da-41f3b3643fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'subject', 'choices', 'answer'],\n",
       "    num_rows: 1531\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmlu_val = mmlu['validation']\n",
    "mmlu_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7789212-41f4-4fb7-a51d-835b426b5ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66e5022e-42e7-46c9-bf07-ae3f9c0ef79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e68307d56324e5295037dcff68dc1f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1531 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response_dict = {}\n",
    "\n",
    "bar = tqdm(range(len(mmlu_val)))\n",
    "for id in range(len(mmlu_val)):\n",
    "    question = mmlu_val[id]['question'] + ' Choices : {}'.format(mmlu_val[id]['choices'])\n",
    "    \n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o\",\n",
    "        instructions=\"Classify the following question based on its difficulty for a high school student. Choose A or B from the following options : A) Difficult for a high school student. B) Easy for a high school student.\",\n",
    "        input=question,\n",
    "    )\n",
    "\n",
    "    response_dict[id] = response.output_text\n",
    "\n",
    "    bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6c880423-0433-4688-a664-770fb5fe5027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the total number of sixth-grade students, let \\( x \\) be the total number of students.\n",
      "\n",
      "The problem states that 24% of the students purchased their lunch, and 190 students brought their lunch from home, which means 76% of the students brought their lunch.\n",
      "\n",
      "Thus, \n",
      "\n",
      "0.76 of \\( x \\) is equal to 190. \n",
      "\n",
      "Set up the equation:\n",
      "\n",
      "\\[\n",
      "0.76x = 190\n",
      "\\]\n",
      "\n",
      "To find \\( x \\), divide both sides by 0.76:\n",
      "\n",
      "\\[\n",
      "x = \\frac{190}{0.76}\n",
      "\\]\n",
      "\n",
      "Calculate the division:\n",
      "\n",
      "\\[\n",
      "x = 250\n",
      "\\]\n",
      "\n",
      "So, the total number of students is 250. The correct choice is '250'.\n",
      "\n",
      "Thus, the answer is B) Easy for a high school student.\n"
     ]
    }
   ],
   "source": [
    "mmlu_gpt4o_easy = {'question':[], 'choices':[], 'answer':[]}\n",
    "mmlu_gpt4o_difficult = {'question':[], 'choices':[], 'answer':[]}\n",
    "err_count = 0\n",
    "\n",
    "for id in range(len(mmlu_val)):\n",
    "    \n",
    "    question = mmlu_val[id]['question']\n",
    "    choices = mmlu_val[id]['choices']\n",
    "    answer = mmlu_val[id]['answer']\n",
    "\n",
    "    response = response_dict[id]\n",
    "    option = response.split(')')[0]\n",
    "    \n",
    "    if option == 'A':\n",
    "        mmlu_gpt4o_difficult['question'].append(question)\n",
    "        mmlu_gpt4o_difficult['choices'].append(choices)\n",
    "        mmlu_gpt4o_difficult['answer'].append(answer)\n",
    "\n",
    "    elif option == 'B':\n",
    "        mmlu_gpt4o_easy['question'].append(question)\n",
    "        mmlu_gpt4o_easy['choices'].append(choices)\n",
    "        mmlu_gpt4o_easy['answer'].append(answer)\n",
    "        \n",
    "    else:\n",
    "        print(response)\n",
    "        err_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "867d1e6d-22e4-42e9-91ed-c019c595886f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "668ed09b-58fa-4d30-8fbf-babd7a96499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_gpt4o_easy = Dataset.from_dict(mmlu_gpt4o_easy)\n",
    "mmlu_gpt4o_hard = Dataset.from_dict(mmlu_gpt4o_difficult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "543bb990-c1eb-4f75-8d5f-a26f6c316c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample\n",
    "num_samples = min(len(mmlu_gpt4o_easy), len(mmlu_gpt4o_hard))\n",
    "seed = 42\n",
    "\n",
    "mmlu_gpt4o_easy = mmlu_gpt4o_easy.shuffle(seed=seed).select(list(range(num_samples)))\n",
    "mmlu_gpt4o_hard = mmlu_gpt4o_hard.shuffle(seed=seed).select(list(range(num_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ba29a899-fa32-4002-9da5-2fd64b5ca397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy config\n",
    "mmlu_gpt4o_easy = DatasetDict({'test':mmlu_gpt4o_easy})\n",
    "# hard config\n",
    "mmlu_gpt4o_hard = DatasetDict({'test':mmlu_gpt4o_hard})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f2dec7b6-e1cc-4c31-adb1-42ba59915d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04207c307134a759c480ccf4966257e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1ad55219934249bcbfc29b053125c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8834c491a707408887c3dbde6d990893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0149810cadef48c1af99d28fe37ceb4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2351cd7771a24bf68160a0e9a0a1f2b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/361 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Ujan/mmlu_gpt4o/commit/a78ec6b3e6987250e8cfffa2f951ea7ba328d374', commit_message='Upload dataset', commit_description='', oid='a78ec6b3e6987250e8cfffa2f951ea7ba328d374', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/Ujan/mmlu_gpt4o', endpoint='https://huggingface.co', repo_type='dataset', repo_id='Ujan/mmlu_gpt4o'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmlu_gpt4o_easy.push_to_hub('Ujan/mmlu_gpt4o', config_name='easy')\n",
    "mmlu_gpt4o_hard.push_to_hub('Ujan/mmlu_gpt4o', config_name='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb9792-b59b-4584-ae28-eeef51c51948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
